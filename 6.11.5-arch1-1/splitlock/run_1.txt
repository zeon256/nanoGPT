[2024-12-27 18:20:18] tokens per iteration will be: 16,384
[2024-12-27 18:20:18] found vocab_size = 65 (inside data/shakespeare_char/meta.pkl)
[2024-12-27 18:20:18] Initializing a new model from scratch
/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/train.py:257: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == "float16"))
Overriding config with config/train_shakespeare_char.py:
# train a miniature character-level shakespeare model
# good for debugging and playing on macbooks and such

out_dir = 'out-shakespeare-char'
eval_interval = 250 # keep frequent because we'll overfit
eval_iters = 200
log_interval = 10 # don't print too too often

# we expect to overfit on this small dataset, so only save when val improves
always_save_checkpoint = False

wandb_log = False # override via command line if you like
wandb_project = 'shakespeare-char'
wandb_run_name = 'mini-gpt'

dataset = 'shakespeare_char'
gradient_accumulation_steps = 1
batch_size = 64
block_size = 256 # context of up to 256 previous characters

# baby GPT model :)
n_layer = 6
n_head = 6
n_embd = 384
dropout = 0.2

learning_rate = 1e-3 # with baby networks can afford to go a bit higher
max_iters = 5000
lr_decay_iters = 5000 # make equal to max_iters usually
min_lr = 1e-4 # learning_rate / 10 usually
beta2 = 0.99 # make a bit bigger because number of tokens per iter is small

warmup_iters = 100 # not super necessary potentially

# on macbook also add
# device = 'cpu'  # run on cpu only
# compile = False # do not torch compile the model

Overriding: max_iters = 1000
Overriding: results_path = ./6.11.5-arch1-1/baseline/run_1.json
number of parameters: 10.65M
num decayed parameter tensors: 26, with 10,740,096 parameters
num non-decayed parameter tensors: 13, with 4,992 parameters
Traceback (most recent call last):
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/train.py", line 260, in <module>
    optimizer = model.configure_optimizers(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/model.py", line 284, in configure_optimizers
    optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/optim/adamw.py", line 77, in __init__
    super().__init__(params, defaults)
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py", line 371, in __init__
    self.add_param_group(cast(dict, param_group))
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_compile.py", line 27, in inner
    import torch._dynamo
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_dynamo/__init__.py", line 39, in <module>
    from .polyfills import loader as _  # usort: skip # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_dynamo/polyfills/loader.py", line 22, in <module>
    POLYFILLED_MODULES: Tuple["ModuleType", ...] = tuple(
                                                   ^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_dynamo/polyfills/loader.py", line 23, in <genexpr>
    importlib.import_module(f".{submodule}", package=polyfills.__name__)
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_dynamo/polyfills/builtins.py", line 23, in <module>
    @substitute_in_graph(builtins.all, can_constant_fold_through=True)
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py", line 312, in wrapper
    rule_map: Dict[Any, Type[VariableTracker]] = get_torch_obj_rule_map()
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py", line 2860, in get_torch_obj_rule_map
    obj = load_object(k)
          ^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py", line 2891, in load_object
    val = _load_obj_from_str(x[0])
          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py", line 2875, in _load_obj_from_str
    return getattr(importlib.import_module(module), obj_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_higher_order_ops/map.py", line 6, in <module>
    from torch._functorch.aot_autograd import AOTConfig, create_joint
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py", line 128, in <module>
    from .partitioners import default_partition
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_functorch/partitioners.py", line 15, in <module>
    import torch._inductor.inductor_prims
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_inductor/inductor_prims.py", line 168, in <module>
    _low_memory_max_pool2d_with_offsets = make_prim(
                                          ^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_inductor/inductor_prims.py", line 31, in make_prim
    return _prims._make_prim(
           ^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_prims/__init__.py", line 319, in _make_prim
    prim_def = torch.library.custom_op(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_library/custom_ops.py", line 157, in custom_op
    return inner(fn)
           ^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_library/custom_ops.py", line 138, in inner
    result = CustomOpDef(namespace, opname, schema_str, fn)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_library/custom_ops.py", line 186, in __init__
    self._register_to_dispatcher()
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_library/custom_ops.py", line 618, in _register_to_dispatcher
    autograd_impl = autograd.make_autograd_impl(self._opoverload, self)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/Documents/school/Y4S1/FYP/nanoGPT/.venv/lib/python3.12/site-packages/torch/_library/autograd.py", line 28, in make_autograd_impl
    @dataclass
     ^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/dataclasses.py", line 1275, in dataclass
    return wrap(cls)
           ^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/dataclasses.py", line 1265, in wrap
    return _process_class(cls, init, repr, eq, order, unsafe_hash,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/dataclasses.py", line 1134, in _process_class
    text_sig = str(inspect.signature(cls)).replace(' -> None', '')
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/inspect.py", line 3341, in signature
    return Signature.from_callable(obj, follow_wrapped=follow_wrapped,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/inspect.py", line 3081, in from_callable
    return _signature_from_callable(obj, sigcls=cls,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/inspect.py", line 2615, in _signature_from_callable
    init = _signature_get_user_defined_method(obj, '__init__')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/inspect.py", line 2034, in _signature_get_user_defined_method
    meth = getattr_static(cls, method_name, None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/inspect.py", line 1864, in getattr_static
    klass_result = _check_class(klass, attr)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/inspect.py", line 1804, in _check_class
    if _shadowed_dict(type(entry)) is _sentinel and attr in entry.__dict__:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zeon256/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/inspect.py", line 1836, in _shadowed_dict
    return _shadowed_dict_from_weakref_mro_tuple(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
